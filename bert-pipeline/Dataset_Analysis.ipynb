{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsZvic2YxnTz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import f1_score,confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples_prediction(df):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        #labels = row[LABEL_HOT_VECTOR].strip('][').split(', ')\n",
    "        #labels = [float(x) for x in labels]\n",
    "        labels = list(row[label_list_text])\n",
    "        examples.append(labels)\n",
    "        \n",
    "    return pd.DataFrame(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    n = 2  # index of the second proability to get labeled \n",
    "\n",
    "    index = np.argsort(x.values.flatten().tolist())[-n:][0]\n",
    "    print(f\"index is {index}\")\n",
    "    label  = label_list_text[index]\n",
    "    print(f\"label is {label}\")\n",
    "    \n",
    "    return label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_experiment_df(test):\n",
    "    test_predictions = [x[0]['probabilities'] for x in zip(getListPrediction(in_sentences=list(test[DATA_COLUMN])))]\n",
    "    test_live_labels = np.array(test_predictions).argmax(axis=1)\n",
    "    test['Predicted label'] = [label_list_text[x] for x in test_live_labels] # appending the labels to the dataframe\n",
    "    \n",
    "    probabilities_df_live = pd.DataFrame(test_predictions) # creating a proabilities dataset\n",
    "    probabilities_df_live.columns = [x + \" Predicted\"for x in label_list_text] # naming the columns\n",
    "    probabilities_df_live['Predicted label 2'] = probabilities_df_live.apply(lambda x:f(x),axis=1)\n",
    "    \n",
    "    #print(test)\n",
    "    #label_df = create_examples_prediction(test)\n",
    "    #label_df.columns = label_list_text\n",
    "    #label_df['label 2'] = label_df.apply(lambda x:f(x),axis=1)\n",
    "\n",
    "    test.reset_index(inplace=True,drop=True) # resetting index \n",
    "\n",
    "    experiment_df = pd.concat([test,probabilities_df_live],axis=1, ignore_index=False)\n",
    "    experiment_df = experiment_df.reindex(sorted(experiment_df.columns), axis=1)\n",
    "    return test,experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListPrediction(in_sentences):\n",
    "    #1\n",
    "    input_examples = [InputExample(guid=\"\", text_a = x, text_b = None, labels = [0]*len(label_list)) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "    \n",
    "    #2\n",
    "    input_features = convert_examples_to_features(input_examples, MAX_SEQ_LENGTH, tokenizer)\n",
    "    \n",
    "    #3\n",
    "    predict_input_fn = input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    \n",
    "    print(input_features[0].input_ids)\n",
    "    #4\n",
    "    predictions = estimator.predict(input_fn=predict_input_fn,yield_single_examples=True)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_normalize_active=False\n",
    "\n",
    "def get_confusion_matrix(y_test,predicted,labels):\n",
    "    class_names=labels\n",
    "    # plotting confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plot_confusion_matrix(y_test, predicted, classes=class_names,\n",
    "                        title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(y_test, predicted, classes=class_names, normalize=True,\n",
    "                        title='Normalized confusion matrix')\n",
    "    plt.show()\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes =classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        test =1\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    #fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_bert(df,test_size):\n",
    "    \n",
    "    #print(\"Filling missing values\")\n",
    "    #df[DATA_COLUMN] = df[DATA_COLUMN].fillna('_NA_')\n",
    "    \n",
    "    print(\"Splitting dataframe with shape {} into training and test datasets\".format(df.shape))\n",
    "    X_train, X_test  = train_test_split(df, test_size=test_size, random_state=2018,stratify = df[LABEL_COLUMN_RAW])\n",
    "\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(NAME,mapping_index,excluded_categories):\n",
    "    df = pd.read_csv(PATH+NAME+'.csv',sep =',')\n",
    "    \n",
    "    #df[LABEL_COLUMN_RAW] = df[LABEL_COLUMN_RAW].fillna(\"Other\")\n",
    "\n",
    "    \n",
    "    df = df[df['is_stressor'] == 1]\n",
    "    df = df[df[LABEL_COLUMN_RAW] != 'Not Stressful']\n",
    "    #df.columns = [LABEL_COLUMN_RAW,'Severity',DATA_COLUMN,'Source']\n",
    "    \n",
    "    if excluded_categories is not None:\n",
    "        for category in excluded_categories:\n",
    "\n",
    "            df = df[df[LABEL_COLUMN_RAW] !=category]\n",
    "\n",
    "    label_list=[]\n",
    "    label_list_final =[]\n",
    "    if(mapping_index is None):\n",
    "        df[LABEL_COLUMN_RAW] = df[LABEL_COLUMN_RAW].astype('category')\n",
    "        df[LABEL_COLUMN], mapping_index = pd.Series(df[LABEL_COLUMN_RAW]).factorize() #uses pandas factorize() to convert to numerical index\n",
    "        \n",
    "  \n",
    "    else:\n",
    "        df[LABEL_COLUMN] = df[LABEL_COLUMN_RAW].apply(lambda x: mapping_index.get_loc(x))\n",
    "    \n",
    "    label_list_final = [None] * len(mapping_index.categories)\n",
    "    label_list_number = [None] * len(mapping_index.categories)\n",
    "\n",
    "    for index,ele in enumerate(list(mapping_index.categories)):\n",
    "        lindex = mapping_index.get_loc(ele)\n",
    "        label_list_number[lindex] = lindex\n",
    "        label_list_final[lindex] = ele\n",
    "    \n",
    "    frequency_dict = df[LABEL_COLUMN_RAW].value_counts().to_dict()\n",
    "    df[\"class_freq\"] = df[LABEL_COLUMN_RAW].apply(lambda x: frequency_dict[x])\n",
    "    \n",
    "    \n",
    "    return df,mapping_index,label_list_number,label_list_final\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Require user changes > Start Here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './datasets/'\n",
    "TODAY_DATE = \"27_04_2020/\"\n",
    "EXPERIMENT_NAME = 'main_turk_analysis_of_5_turkers_popbots_test_live_10votes'\n",
    "EXPERIMENTS_PATH = PATH + 'experiments/'+TODAY_DATE+EXPERIMENT_NAME\n",
    "if not os.path.exists(PATH + 'experiments/'+TODAY_DATE):\n",
    "    os.mkdir(PATH + 'experiments/'+TODAY_DATE)\n",
    "if not os.path.exists(EXPERIMENTS_PATH):\n",
    "    os.mkdir(EXPERIMENTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjwJ4bTeWXD8"
   },
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 1000\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# We'll set sequences to be at most 32 tokens long.\n",
    "MAX_SEQ_LENGTH = 32\n",
    "\n",
    "\n",
    "OUTPUT_DIR = './models/'+EXPERIMENT_NAME+ '/' #_01_04_2020/\n",
    "\n",
    "##use downloaded model, change path accordingly\n",
    "BERT_VOCAB= './bert_model/uncased_L-12_H-768_A-12/vocab.txt'\n",
    "BERT_INIT_CHKPNT = './bert_model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "BERT_CONFIG = './bert_model/uncased_L-12_H-768_A-12/bert_config.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test percentage is 0.050670241286863274\n",
      "Splitting dataframe with shape (1865, 21) into training and test datasets\n",
      "Normal label list is [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "The labels text is ['Other', 'Everyday Decision Making', 'Work', 'Social Relationships', 'Financial Problem', 'Emotional Turmoil', 'Health, Fatigue, or Physical Pain', 'School', 'Family Issues']\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = '2020-04-28-Main-turk-aggregation-5-turkers'\n",
    "\n",
    "DATA_COLUMN = 'Input.text'\n",
    "LABEL_COLUMN_RAW = 'labels'#'Answer.Label'\n",
    "LABEL_COLUMN = 'label_numeric'\n",
    "\n",
    "MTURK_NAME = 'mTurk_synthetic'\n",
    "LIVE_NAME = 'popbots_live'\n",
    "\n",
    "LABEL_HOT_VECTOR = 'label_conf'\n",
    "\n",
    "#dataset,mapping_index,label_list, label_list_text = open_dataset('mturk900balanced',None)\n",
    "\n",
    "EXCLUDED_CATEGORIES = None #['Other'] #None # # if nothing to exclude put None, THIS ALWAYS MUST BE A LIST \n",
    "mapping_dict = {'Other': 0, 'Everyday Decision Making': 1, 'Work': 2, 'Social Relationships': 3, 'Financial Problem': 4, 'Emotional Turmoil': 5, 'Health, Fatigue, or Physical Pain': 6, 'School': 7, 'Family Issues': 8}#,'Not Stressful':9}\n",
    "mapping_index = pd.CategoricalIndex([key for key,value in mapping_dict.items()])\n",
    "\n",
    "dataset,mapping_index,label_list, label_list_text = open_dataset(DATASET_NAME,mapping_index,EXCLUDED_CATEGORIES)\n",
    "\n",
    "#dataset = dataset[dataset['is_stressor'] == 1]\n",
    "\n",
    "test_on_mturk_and_popbots_live = True # include live data in training + include mturk in testing\n",
    "\n",
    "\n",
    "if test_on_mturk_and_popbots_live:\n",
    "    \n",
    "    mturk = dataset[dataset['Source']== MTURK_NAME]\n",
    "    live = dataset[dataset['Source']== LIVE_NAME]\n",
    "    live = live.sample(frac=1).reset_index(drop=True) # shuffle live\n",
    "    \n",
    "    PERCENTAGE_LIVE_TEST = 70\n",
    "    \n",
    "    TEST_PERCENTAGE = len(live)/((100/PERCENTAGE_LIVE_TEST)*len(mturk))  # given to set the percentage of mturk used as test set to have 50/50\n",
    "    \n",
    "    print(f\"Test percentage is {TEST_PERCENTAGE}\")\n",
    "\n",
    "    train,test = data_prep_bert(mturk,TEST_PERCENTAGE) # test size from mturk \n",
    "    \n",
    "    train = train.append(live.loc[0:int((1-(PERCENTAGE_LIVE_TEST/100))*len(live))]) # taking 1/2 of that dataset for training\n",
    "    \n",
    "    test = test.append(live.loc[int(len(live)*(1-(PERCENTAGE_LIVE_TEST/100))):int(len(live))]) # taking 1/2 of live dataset for testing\n",
    "else:\n",
    "    # or taking live only for testing\n",
    "    train,test = dataset[dataset['Source']== MTURK_NAME],dataset[dataset['Source']== LIVE_NAME] \n",
    "\n",
    "#train = train[train['is_stressor'] == 1] # remove only non stressor from train\n",
    "\n",
    "#print(f\"Dataset has {len(dataset)} training examples\")\n",
    "print(f\"Normal label list is {label_list}\")\n",
    "print(f\"The labels text is {label_list_text}\")\n",
    "\n",
    "#Export train test to csv\n",
    "#train.to_csv(PATH+'900_CSV_SPLITTED/train.csv')\n",
    "#test.to_csv(PATH+'900_CSV_SPLITTED/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_columns = ['category', 'nb_sentence','distinct_word_nb','distinc_word_per_sentence']\n",
    "count_results = pd.DataFrame(columns = df_columns)\n",
    "\n",
    "for category in label_list_text:\n",
    "    \n",
    "    category_df = dataset[dataset[LABEL_COLUMN_RAW] == category]\n",
    "    category_df[DATA_COLUMN].str.lower().str.split()\n",
    "    results = set()\n",
    "    category_df[DATA_COLUMN].str.lower().str.split().apply(results.update)\n",
    "    count_results = count_results.append({'category':category,'nb_sentence':len(category_df),'distinct_word_nb':len(list(results)),'distinc_word_per_sentence':len(list(results))/len(category_df)}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>nb_sentence</th>\n",
       "      <th>distinct_word_nb</th>\n",
       "      <th>distinc_word_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Work</td>\n",
       "      <td>709</td>\n",
       "      <td>1330</td>\n",
       "      <td>1.875882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Financial Problem</td>\n",
       "      <td>339</td>\n",
       "      <td>754</td>\n",
       "      <td>2.224189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>School</td>\n",
       "      <td>158</td>\n",
       "      <td>409</td>\n",
       "      <td>2.588608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Family Issues</td>\n",
       "      <td>235</td>\n",
       "      <td>758</td>\n",
       "      <td>3.225532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Health, Fatigue, or Physical Pain</td>\n",
       "      <td>129</td>\n",
       "      <td>434</td>\n",
       "      <td>3.364341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyday Decision Making</td>\n",
       "      <td>116</td>\n",
       "      <td>415</td>\n",
       "      <td>3.577586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social Relationships</td>\n",
       "      <td>127</td>\n",
       "      <td>470</td>\n",
       "      <td>3.700787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>111</td>\n",
       "      <td>436</td>\n",
       "      <td>3.927928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emotional Turmoil</td>\n",
       "      <td>76</td>\n",
       "      <td>338</td>\n",
       "      <td>4.447368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            category nb_sentence distinct_word_nb  \\\n",
       "2                               Work         709             1330   \n",
       "4                  Financial Problem         339              754   \n",
       "7                             School         158              409   \n",
       "8                      Family Issues         235              758   \n",
       "6  Health, Fatigue, or Physical Pain         129              434   \n",
       "1           Everyday Decision Making         116              415   \n",
       "3               Social Relationships         127              470   \n",
       "0                              Other         111              436   \n",
       "5                  Emotional Turmoil          76              338   \n",
       "\n",
       "   distinc_word_per_sentence  \n",
       "2                   1.875882  \n",
       "4                   2.224189  \n",
       "7                   2.588608  \n",
       "8                   3.225532  \n",
       "6                   3.364341  \n",
       "1                   3.577586  \n",
       "3                   3.700787  \n",
       "0                   3.927928  \n",
       "5                   4.447368  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_results.sort_values(by=['distinc_word_per_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set and test set analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_info(train,test):\n",
    "    print(f\"Train size {len(train)} with {len(train[train['Source']== LIVE_NAME])} from Popbots and {len(train[train['Source']== MTURK_NAME])} from mturk\")\n",
    "    print(f\"Test size {len(test)} with {len(test[test['Source']== LIVE_NAME])} from Popbots and {len(test[test['Source']== MTURK_NAME])} from mturk\")\n",
    "    \n",
    "    print('\\nTraining distribution:')\n",
    "    print(pd.pivot_table(train[[LABEL_COLUMN_RAW, 'Source']],index=[LABEL_COLUMN_RAW, 'Source'],columns=None, aggfunc=len)) #.to_clipboard(excel=True)\n",
    "          \n",
    "    print('\\nTesting distribution:')\n",
    "    print(pd.pivot_table(test[[LABEL_COLUMN_RAW, 'Source']],index=[LABEL_COLUMN_RAW, 'Source'],columns=None, aggfunc=len)) #.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True) #reshuffle everything\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All dataset distribution:\n",
      "labels                             Source         \n",
      "Emotional Turmoil                  mTurk_synthetic     70\n",
      "                                   popbots_live         6\n",
      "Everyday Decision Making           mTurk_synthetic     99\n",
      "                                   popbots_live        17\n",
      "Family Issues                      mTurk_synthetic    225\n",
      "                                   popbots_live        10\n",
      "Financial Problem                  mTurk_synthetic    337\n",
      "                                   popbots_live         2\n",
      "Health, Fatigue, or Physical Pain  mTurk_synthetic    109\n",
      "                                   popbots_live        20\n",
      "Other                              mTurk_synthetic     97\n",
      "                                   popbots_live        14\n",
      "School                             mTurk_synthetic    145\n",
      "                                   popbots_live        13\n",
      "Social Relationships               mTurk_synthetic    113\n",
      "                                   popbots_live        14\n",
      "Work                               mTurk_synthetic    670\n",
      "                                   popbots_live        39\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nAll dataset distribution:')\n",
    "print(pd.pivot_table(dataset[[LABEL_COLUMN_RAW, 'Source']],index=[LABEL_COLUMN_RAW, 'Source'],columns=None, aggfunc=len)) #.to_clipboard(excel=T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 1811 with 41 from Popbots and 1770 from mturk\n",
      "Test size 190 with 95 from Popbots and 95 from mturk\n",
      "\n",
      "Training distribution:\n",
      "labels                             Source         \n",
      "Emotional Turmoil                  mTurk_synthetic     66\n",
      "                                   popbots_live         2\n",
      "Everyday Decision Making           mTurk_synthetic     94\n",
      "                                   popbots_live         4\n",
      "Family Issues                      mTurk_synthetic    214\n",
      "                                   popbots_live         2\n",
      "Financial Problem                  mTurk_synthetic    320\n",
      "Health, Fatigue, or Physical Pain  mTurk_synthetic    103\n",
      "                                   popbots_live         6\n",
      "Other                              mTurk_synthetic     92\n",
      "                                   popbots_live         5\n",
      "School                             mTurk_synthetic    138\n",
      "                                   popbots_live         3\n",
      "Social Relationships               mTurk_synthetic    107\n",
      "                                   popbots_live         3\n",
      "Work                               mTurk_synthetic    636\n",
      "                                   popbots_live        16\n",
      "dtype: int64\n",
      "\n",
      "Testing distribution:\n",
      "labels                             Source         \n",
      "Emotional Turmoil                  mTurk_synthetic     4\n",
      "                                   popbots_live        4\n",
      "Everyday Decision Making           mTurk_synthetic     5\n",
      "                                   popbots_live       13\n",
      "Family Issues                      mTurk_synthetic    11\n",
      "                                   popbots_live        8\n",
      "Financial Problem                  mTurk_synthetic    17\n",
      "                                   popbots_live        2\n",
      "Health, Fatigue, or Physical Pain  mTurk_synthetic     6\n",
      "                                   popbots_live       15\n",
      "Other                              mTurk_synthetic     5\n",
      "                                   popbots_live        9\n",
      "School                             mTurk_synthetic     7\n",
      "                                   popbots_live       10\n",
      "Social Relationships               mTurk_synthetic     6\n",
      "                                   popbots_live       11\n",
      "Work                               mTurk_synthetic    34\n",
      "                                   popbots_live       23\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_dataset_info(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step to reduce the most dominant categories and balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_cutoff = 100 # all the categories which had less than 100 example won't be sampled down\n",
    "total_training_size = 1501\n",
    "\n",
    "REVERSE_FREQ = 'Max_reverse_sampling_chance'\n",
    "train[REVERSE_FREQ] = train['class_freq'].apply(lambda x: (max(train['class_freq'])/x)) \n",
    "\n",
    "sampling_boolean = (train['Source'] != LIVE_NAME) & (train['class_freq'].astype(float) > sampling_cutoff) \n",
    "\n",
    "\n",
    "train_to_be_balanced = train[sampling_boolean]\n",
    "train_not_resampled = train[~sampling_boolean]\n",
    "\n",
    "train_temp = train_to_be_balanced.sample(n=(total_training_size-len(train_not_resampled)), weights=REVERSE_FREQ, random_state=2020)\n",
    "train = pd.concat([train_temp,train_not_resampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 1501 with 0 from Popbots and 1501 from mturk\n",
      "Test size 135 with 135 from Popbots and 0 from mturk\n",
      "\n",
      "Training distribution:\n",
      "labels                             Source         \n",
      "Emotional Turmoil                  mTurk_synthetic     70\n",
      "Everyday Decision Making           mTurk_synthetic     99\n",
      "Family Issues                      mTurk_synthetic    209\n",
      "Financial Problem                  mTurk_synthetic    273\n",
      "Health, Fatigue, or Physical Pain  mTurk_synthetic    109\n",
      "Other                              mTurk_synthetic     97\n",
      "School                             mTurk_synthetic    140\n",
      "Social Relationships               mTurk_synthetic    113\n",
      "Work                               mTurk_synthetic    391\n",
      "dtype: int64\n",
      "\n",
      "Testing distribution:\n",
      "labels                             Source      \n",
      "Emotional Turmoil                  popbots_live     6\n",
      "Everyday Decision Making           popbots_live    17\n",
      "Family Issues                      popbots_live    10\n",
      "Financial Problem                  popbots_live     2\n",
      "Health, Fatigue, or Physical Pain  popbots_live    20\n",
      "Other                              popbots_live    14\n",
      "School                             popbots_live    13\n",
      "Social Relationships               popbots_live    14\n",
      "Work                               popbots_live    39\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print_dataset_info(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalIndex(['Other', 'Everyday Decision Making', 'Work',\n",
       "                  'Social Relationships', 'Financial Problem',\n",
       "                  'Emotional Turmoil', 'Health, Fatigue, or Physical Pain',\n",
       "                  'School', 'Family Issues'],\n",
       "                 categories=['Emotional Turmoil', 'Everyday Decision Making', 'Family Issues', 'Financial Problem', 'Health, Fatigue, or Physical Pain', 'Other', 'School', 'Social Relationships', ...], ordered=False, dtype='category')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(EXPERIMENTS_PATH+'/TRAIN_'+DATASET_NAME+'.csv')\n",
    "test.to_csv(EXPERIMENTS_PATH+'/TEST_'+DATASET_NAME+'.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python TensorFlow 1.15",
   "language": "python",
   "name": "tf1.1_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
